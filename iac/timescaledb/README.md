# TimescaleDB

Contents:
- [Prerequisites](#prerequisites)
- [Configuration](#configuration)
  - [Tuning PostgreSQL Configuration](#tuning-postgresql-configuration)
- [Installation](#installation)
- [Maintenance](#maintenance)
  - [Start, Stop, Restart](#start-stop-restart)
  - [Logging](#logging)
- [TimescaleDB Concepts and Tips](#timescaledb-concepts-and-tips)
  - [Hypertables](#hypertables)
  - [Compression](#compression)
  - [Data Retention](#data-retention)
  - [Continuous Aggregates](#continuous-aggregates)

[TimescaleDB](https://docs.timescale.com/) is an extension of [PostgreSQL](https://www.postgresql.org/), the most prominent open-source relational database. It enhances PostgreSQL with advanced features for ingesting, storing, and querying time-series data.

This directory contains templates for running TimescaleDB on Ubuntu. The installation serves as a host for analytical databases, which store curated datasets generated by the Airflow data pipelines. It can also support application state databases used by data analytics tools, such as [Airflow](../airflow/README.md).

## Prerequisites

Before running the installation script, ensure the following:

1. **Platform**: Ubuntu/Linux server.
2. **Privileges**: Sudo access for installing packages and configuring system services.
3. **Network**: Internet connection for downloading PostgreSQL, TimescaleDB, and extension packages.

## Configuration

TimescaleDB is installed on Ubuntu using the automated [`timescaledb_install.sh`](timescaledb_install.sh) script. This script applies configuration settings from [`postgresql.conf`](postgresql.conf) and [`pg_hba.conf`](pg_hba.conf):

- **[`pg_hba.conf`](pg_hba.conf):** Manages client authentication. By default, all local Unix connections are allowed, streamlining access for containerized applications on the same host.
- **[`postgresql.conf`](postgresql.conf):** Key parameters are tuned according to the system's hardware (vCPUs, memory) for optimal performance.

### Tuning PostgreSQL Configuration

TimescaleDB offers built-in tuning functionality to help optimize database performance according to your system's hardware. The [TimescaleDB Tune tool](https://docs.timescale.com/self-hosted/latest/configuration/timescaledb-tune/) analyzes your system resources and automatically adjusts configuration parameters in [`postgresql.conf`](postgresql.conf) for optimal performance. This tool can be run after installation to fine-tune settings based on your server's specific hardware configuration.

## Installation

Run the installation script from the `iac/timescaledb` directory:

```bash
bash timescaledb_install.sh
```

Below is an overview of the steps performed by the script:

1. Add the PostgreSQL APT repository and install required dependencies using the repository setup script.
2. Add the TimescaleDB third-party repository to the system's sources list and install the TimescaleDB GPG key for package verification.
3. Install the TimescaleDB package for PostgreSQL 17.
4. Restart PostgreSQL and configure TimescaleDB by copying the [`pg_hba.conf`](pg_hba.conf) and [`postgresql.conf`](postgresql.conf) files to the appropriate PostgreSQL directory.
5. Download and build the [`pgvector`](https://github.com/pgvector/pgvector) and [`pgvectorscale`](https://github.com/timescale/pgvectorscale) extensions:
    - Install Rust and its dependencies.
    - Download and build the `pgvector` and `pgvectorscale` extensions.
    - Install the `cargo-pgrx` tool and initialize it for PostgreSQL 17.
    - Build and install the `pgvectorscale` extension.

After installation completes:

1. Set the postgres user password manually (see MANUAL_STEPS section in the script).
2. Restart PostgreSQL to ensure all changes take effect:
   ```bash
   sudo systemctl restart postgresql
   ```
3. Run the database initialization scripts from `dags/` as described in the main [README.md](../../README.md#database-initialization).

## Maintenance

### Start, Stop, Restart

Use the `systemctl` utility to manage the TimescaleDB service on your server.
PostgreSQL operates as a [systemd](https://systemd.io/) service, which manages the underlying processes and data files. Maintenance tasks that cannot be performed through SQL commands — such as starting, stopping, or restarting the database — should be handled with `systemctl`, the standard tool for managing systemd services.

**Start service:**
```bash
sudo systemctl start postgresql
```

**Restart service:**
```bash
sudo systemctl restart postgresql
```

**Stop service:**
```bash
sudo systemctl stop postgresql
```

**Check status:**
```bash
systemctl status postgresql
```

On Ubuntu, PostgreSQL is managed by systemd using two types of service units:

- **Template unit:**
    The main configuration template is located at `/usr/lib/systemd/system/postgresql@.service`. This template defines how individual PostgreSQL instances are started and managed.

- **Wrapper unit:**
    The `/lib/systemd/system/postgresql.service` unit acts as a "meta" or wrapper service. It does not directly run the PostgreSQL server daemon. Instead, it provides a unified control interface for all PostgreSQL instances on the system.
    - `Type=oneshot` with `ExecStart=/bin/true` and `RemainAfterExit=yes` is used, meaning the service executes a command and then exits, without keeping a process running in the foreground.
    - This pattern allows commands like `systemctl start postgresql` or `systemctl stop postgresql` to control all PostgreSQL instances collectively.

For most administrative tasks, you can use the `postgresql.service` unit for convenience, but instance-specific management is handled by the template unit.

### Logging

PostgreSQL provides extensive logging configuration options. By default, logs are written to a text file, with log rotation configured to retain logs for 1 day or up to a maximum file size of 10 MB. On Ubuntu, the default log file path is `/var/log/postgresql/postgresql-17-main.log`.

To monitor the most recent log entries:

```bash
tail -n 50 -f /var/log/postgresql/postgresql-17-main.log
```

> **Note:** There may be a variable delay between database actions and log entries appearing in the file, due to how PostgreSQL writes logs. For precise timing, consider alternative logging or monitoring solutions.

## TimescaleDB Concepts and Tips

[TimescaleDB](https://docs.timescale.com/) is a PostgreSQL extension designed to efficiently ingest, store, and query time-series data. Its core abstraction is the [hypertable](https://docs.timescale.com/timescaledb/latest/how-to-guides/hypertables/): a logical table that automatically partitions data into multiple underlying PostgreSQL tables, called chunks, each covering a distinct time range. When you query a hypertable, TimescaleDB intelligently accesses only the relevant chunks, enabling significant performance gains for large-scale time-series workloads.

Hypertables are easy to use — most standard PostgreSQL operations work seamlessly, often with additional optimizations. However, some operations have limitations or special considerations, so it's important to review TimescaleDB's documentation when designing your schema.

Another key feature is the [continuous aggregate](https://docs.timescale.com/use-timescale/latest/continuous-aggregates/), which extends materialized views for time-series data. Continuous aggregates are defined by a `SELECT` query that groups by the time column (and optionally other columns) of a hypertable, and they are incrementally refreshed for efficiency.

Both hypertables and continuous aggregates support advanced features such as [compression](https://docs.timescale.com/use-timescale/latest/compression/) and [data retention](https://docs.timescale.com/use-timescale/latest/data-retention/). Compression leverages columnar storage to reduce disk usage and accelerate analytical queries, while data retention policies automate the removal of old data, keeping your database lean and performant.

### Hypertables

Hypertables are logical tables that TimescaleDB uses to efficiently manage time-series data. Internally, a hypertable consists of many standard PostgreSQL tables called *chunks*, each storing data for a distinct, non-overlapping time interval. Every hypertable requires a `TIMESTAMPTZ` column — referred to as the *time column* — which determines how rows are assigned to chunks.

When creating a hypertable, you specify a *chunk_time_interval* (or *partition_interval* in the newer [`create_hypertable()`](https://docs.timescale.com/api/latest/hypertable/create_hypertable/) API), which defines the duration each chunk covers. Properly sizing this interval is important for balancing query performance, storage efficiency, and maintenance overhead.

#### Design

When designing a hypertable, aim to set the *chunk_time_interval* so that the average uncompressed chunk size is approximately 25% of the available RAM. This helps ensure efficient query performance and resource utilization.
As detailed in the [Compression](#compression) section, compressing every hypertable is strongly recommended to reduce storage costs. However, enabling compression introduces additional constraints that must be considered during schema design.

Keep in mind the following [limitations](https://docs.timescale.com/use-timescale/latest/limitations/) when working with hypertables:

* Time columns used for partitioning (the time dimension) cannot contain NULL values.
* Unique indexes must include all columns that are partitioning dimensions.
* UPDATE statements that would move rows between partitions (chunks) are not supported. This also applies to upserts (`INSERT ... ON CONFLICT UPDATE`).
* Foreign key constraints from one hypertable to another hypertable are not supported.

### Compression

Compression in TimescaleDB reduces storage costs by converting multiple rows that share values in one or more columns — called *segmentby* columns — into a single row. The *segmentby* columns retain their original values, while other columns are stored as arrays of values. Compression and decompression operate at the chunk level for both hypertables and continuous aggregates. Compressed rows are not directly accessible; TimescaleDB transparently decompresses only the necessary data during queries.

Properly configured, compression can shrink a hypertable's disk footprint by 90–95%. For this reason, all hypertables and continuous aggregates should be compressed where practical. The tradeoff is that decompressing data for queries can increase CPU and memory usage and query latency.

To automate compression, define a [compression policy](https://docs.timescale.com/api/latest/compression/add_compression_policy/) on a hypertable or continuous aggregate. This policy automatically compresses chunks older than a specified interval. When a policy is created, any existing chunks older than the interval are compressed in order. You can also manually compress or decompress chunks using [compress_chunk()](https://docs.timescale.com/api/latest/compression/compress_chunk/) and [decompress_chunk()](https://docs.timescale.com/api/latest/compression/decompress_chunk/).
> **Note:** For continuous aggregates with both a compression policy and a [continuous aggregate policy](https://docs.timescale.com/api/latest/continuous-aggregates/add_continuous_aggregate_policy/), the compression interval must be greater than the *start_offset* of the continuous aggregate policy.

> **See Also:**
> - [Building columnar compression in a row-oriented database](https://www.timescale.com/blog/building-columnar-compression-in-a-row-oriented-database/)
> - [About compression](https://docs.timescale.com/use-timescale/latest/compression/about-compression/)

#### Design

Choosing *segmentby* columns is critical for balancing query performance and compression ratio:

1. **Query performance:** Too few *segmentby* columns can slow queries that filter on those columns.
2. **Compression ratio:** More *segmentby* columns generally reduce compression efficiency.

- If every column is a *segmentby* column, compression is ineffective.
- If there are no *segmentby* columns, the entire chunk is compressed into a single row, maximizing compression but potentially harming query performance.

If a hypertable has a UNIQUE constraint or PRIMARY KEY, all columns in the constraint except the time column must be *segmentby* columns. To maximize flexibility, prefer UNIQUE INDEXes over constraints.

**Recommended strategies:**
- Do **not** use the time (or time_bucket) column as a *segmentby* column; chunking already partitions by time, and its high cardinality reduces compression benefits.
- Use non-time columns that are frequently filtered in queries as *segmentby* columns.
- Avoid excessive selectivity: too many *segmentby* columns reduce compression efficiency.

During compression, data is grouped by *segmentby* columns, then ordered by the *orderby* parameter (defaulting to the time column), and divided into timestamp-ordered mini-batches (up to 1,000 rows each). TimescaleDB stores metadata about the minimum and maximum timestamps for each batch, enabling efficient query pruning without full decompression.

*Note:* You can only change *segmentby* columns when all chunks are uncompressed, which is often impractical for large hypertables due to time and disk space requirements.

#### Configuration

To enable compression on a hypertable, set the following parameters:

```sql
ALTER TABLE hypertable_name SET (
    timescaledb.compress = TRUE,
    timescaledb.compress_segmentby = 'col1, col2, ...'
);
```

For continuous aggregates, *segmentby* columns are always the GROUP BY columns, so `timescaledb.compress_segmentby` is not used:

```sql
ALTER MATERIALIZED VIEW cagg_name SET timescaledb.compress = TRUE;
```

To add a compression policy:

```sql
SELECT add_compression_policy('hypertable_name', INTERVAL '1d');
```

Replace `1d` with the desired compression interval. Only one compression policy can exist per hypertable or continuous aggregate. To remove a policy:

```sql
SELECT remove_compression_policy('hypertable_name');
```

#### Restrictions

The following operations are not allowed on hypertables with compressed chunks:

- Adding or dropping UNIQUE constraints or PRIMARY KEYs
- Creating UNIQUE INDEXes
- Altering *segmentby* columns (`timescaledb.compress_segmentby`)
- Using [Timescale SkipScan](https://docs.timescale.com/use-timescale/latest/query-data/skipscan/) on compressed chunks
- Changing column data types

The following operations are highly resource-intensive on compressed chunks and should be avoided:

- `COPY`
- Refreshing continuous aggregates
- Creating indexes that include non-segmentby columns, or when some chunks are compressed and others are not

See also:

* [Compression restrictions](https://docs.timescale.com/api/latest/compression/#restrictions)
* [Modifying a schema with compression](https://docs.timescale.com/use-timescale/latest/compression/modify-a-schema/)

### Data Retention

Data retention in TimescaleDB enables automatic deletion of old data from hypertables and continuous aggregates by removing chunks older than a specified interval. This helps manage storage usage and ensures that only relevant, recent data is retained.

To enable a retention policy, use [`add_retention_policy()`](https://docs.timescale.com/api/latest/data-retention/add_retention_policy/):

```sql
SELECT add_retention_policy('hypertable_name', INTERVAL '60d');
```

Replace `60d` with the desired retention period. Chunks older than this interval will be automatically dropped.

To remove a retention policy, use [`remove_retention_policy()`](https://docs.timescale.com/api/latest/data-retention/remove_retention_policy/):

```sql
SELECT remove_retention_policy('hypertable_name');
```

For more details, refer to the [TimescaleDB data retention documentation](https://docs.timescale.com/use-timescale/latest/data-retention/).

### Continuous Aggregates

[Continuous aggregates](https://docs.timescale.com/use-timescale/latest/continuous-aggregates/about-continuous-aggregates/) are specialized data structures that store the results of aggregation queries (such as those using `GROUP BY`) on a hypertable or another continuous aggregate. While similar to materialized views, continuous aggregates offer several important distinctions:

1. **Source restriction:** The aggregation query must select from exactly one hypertable or continuous aggregate.
2. **Grouping requirement:** The query must include a `GROUP BY` clause.
3. **Time-based grouping:** The `GROUP BY` clause must reference a time column — either the hypertable's time column or a value derived from it using [`time_bucket()`](https://docs.timescale.com/api/latest/hyperfunctions/time_bucket/).
4. **Incremental materialization:** During refreshes, only new or changed data since the last refresh is processed, minimizing unnecessary computation.
5. **Automated refresh:** You can configure a [continuous aggregate policy](https://docs.timescale.com/getting-started/latest/create-cagg/create-cagg-policy/) to automatically refresh aggregates on a schedule.

Continuous aggregates are implemented as hypertables under the hood, known as *materialization hypertables*. Most operations available for hypertables also apply to continuous aggregates. In some cases — such as inspecting chunk information or storage statistics — you may need to reference the materialization hypertable directly.

To list the materialization hypertables for all continuous aggregates, run:

```sql
SELECT * FROM timescaledb_information.continuous_aggregates;
```

---
